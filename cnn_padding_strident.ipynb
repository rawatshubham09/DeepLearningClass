{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6970a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras import Sequential\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84daeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train),(X_test,y_test) = mnist.load_data()\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea285639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662f4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06eaa4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27260166f40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAHSCAYAAAC6vFFPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUKUlEQVR4nO3de+zldX3n8de7zADLxZZZdJZSKhRpvW7H7gRpJMqGylKzCZLGC20a2u1m3Cqp7rK7smSz0o0mdKN0reuSQKTQxEsraqUNvSAxalNkHVhULlUojlvGYabIguhahJnP/jGHzaydG+f7nvmdM/N4JJP5/c457/l88s0hT77nnN/vW2OMAADT/dBKbwAADhWiCgBNRBUAmogqADQRVQBoIqoA0GTVwVzsyDpqHJ1jD+aSANDqifzvR8YYz93dfQc1qkfn2Lyizj2YSwJAq0+PG7+xp/u8/AsATUQVAJpMimpVnV9VX62qB6rqsq5NAcAymjuqVXVEkg8k+fkkL05yUVW9uGtjALBsppypnpnkgTHGg2OM7yf5aJILerYFAMtnSlRPTvI3u3z/0Ow2ADgsHfAfqamqDUk2JMnROeZALwcAK2bKmermJKfs8v2PzW77/4wxrhljrB9jrF+doyYsBwCLbUpUv5jkjKo6raqOTPKmJDf1bAsAls/cL/+OMZ6uqkuS/FmSI5JcN8a4p21nALBkJr2nOsa4OcnNTXsBgKXmNyoBQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQJNVK70BONTUqmn/WR3x3BObdnLwffXfnjr37PZjdkxa+/mnb5t79pi31KS1H77qyLln71z/+5PWfmT7d+eefcXHLp209gv+zRcmzR+KnKkCQBNRBYAmogoATSa9+VNVm5I8kWR7kqfHGOs7NgUAy6jjg0r/dIzxSMO/AwBLzcu/ANBkalRHkj+vqjuqasPuHlBVG6pqY1VtfCpPTlwOABbX1Jd/zx5jbK6q5yW5par+aozxuV0fMMa4Jsk1SfKcWjMmrgcAC2vSmeoYY/Ps721JPpnkzI5NAcAymjuqVXVsVR3/zNdJzktyd9fGAGDZTHn5d22ST1bVM//Oh8cYf9qyKwBYQnNHdYzxYJKfbtwLACw1P1IDAE1EFQCauPQbB8wRLzpj0vw4avXcs9989Y9MWvt7Z81/Oa01Pzz/bJJ8/qenXQrscPUn/+f4uWd/67+dP2nt21/24blnv/7U9yatfeXW18w9+6Of91OO3ZypAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQxPVU2avt5/zM3LNXXf+BSWv/5OojJ82zXJ4a2yfN/6f3/8rcs6u+O+26oj/7sUvmnj1+89OT1j7qkfmvx3rMxtsnrc3f50wVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBOXfmOvjvrqN+eevePvTpm09k+u3jpp/nB06ZazJs0/+J0TJ81ff/qNc88+vmPa5dfW/s5fTppfVtOOGt2cqQJAE1EFgCaiCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAE1EFgCaiCgBNRBUAmogqADQRVQBoIqoA0MT1VNmrp7c8PPfs+3/r9ZPWfvf535179ogvHzdp7S+95f2T5qd41yP/eO7ZB37umElrb39sy6T5X/zZt8w9u+k3Ji2d0/Klaf8ANHCmCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAE1EFgCaiCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJS79xwKz53dsmzT/3j/7h3LPbv/XopLVf8tJ/MffsPa+6btLaN13z6rlnn/fYX05ae6q6bf7Lr5027ekCC8GZKgA0EVUAaCKqANBkn1GtquuqaltV3b3LbWuq6paqun/29wkHdpsAsPj250z1+iTn/8BtlyW5dYxxRpJbZ98DwGFtn1EdY3wuyQ9+lPKCJDfMvr4hyet6twUAy2fe91TXjjG2zL5+OMnapv0AwNKa/EGlMcZIMvZ0f1VtqKqNVbXxqTw5dTkAWFjzRnVrVZ2UJLO/t+3pgWOMa8YY68cY61fnqDmXA4DFN29Ub0py8ezri5N8qmc7ALC89udHaj6S5LYkP1VVD1XVryW5Mslrqur+JD83+x4ADmv7/N2/Y4yL9nDXuc17AYCl5jcqAUATUQWAJqIKAE1cT5WFtf2Rb63Y2k99+8gVW/slv3Tv3LN/e/UR0xbfsX3aPBzmnKkCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaOLSb7AbL3rH1+ae/dWXnTtp7d99/q1zz7769W+dtPbxv/+FSfNwuHOmCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAE1EFgCaiCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAE9dThd3Y/tjjc89+69dfNGnt/3XT9+aevexdvzdp7f/whgsnzY//+cNzz57y7tsmrZ0xps1DA2eqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJq49Bs02/Gl+ybNv+k3/93csx9653smrX3XWdMuHZez5h99ybGXTFr6jGu3zD379IObJq0Nz3CmCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAE1EFgCaiCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAkxpjHLTFnlNrxivq3IO2HhxuxivXTZp/zpUPTZr/yE/82aT5KV74mX859+xP/ebjk9befv+Dk+ZZLp8eN94xxli/u/ucqQJAE1EFgCaiCgBN9hnVqrquqrZV1d273HZFVW2uqrtmf157YLcJAItvf85Ur09y/m5u/+0xxrrZn5t7twUAy2efUR1jfC7JowdhLwCw1Ka8p3pJVX159vLwCW07AoAlNW9Ur05yepJ1SbYkee+eHlhVG6pqY1VtfCpPzrkcACy+uaI6xtg6xtg+xtiR5NokZ+7lsdeMMdaPMdavzlHz7hMAFt5cUa2qk3b59sIkd+/psQBwuFi1rwdU1UeSnJPkxKp6KMk7k5xTVeuSjCSbkrz5wG0RAJbDPqM6xrhoNzd/8ADsBQCWmt+oBABNRBUAmogqADRxPVXg/zli7fMmzX/zjS+Ye/b2d7xv0to/NOEc4Ze+ft6ktR8/+1uT5lkurqcKAAeBqAJAE1EFgCaiCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAE1EFgCaiCgBNRBUAmogqADRZtdIbABbH9q3bJs2v/Z355//u3z89ae1j6si5Z6899Y8nrf3PL3z73LPHfPL2SWuzWJypAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQxPVU4RCy4+x1k+b/+vVHT5p/6bpNc89OuR7qVO9/9OWT5o/51MamnbDsnKkCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaOLSb9Cs1r900vzXfmP+S6Bd+8obJq39qqO/P2l+JT05npp79guPnjZt8R1bps1zyHCmCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAE1EFgCaiCgBNRBUAmogqADQRVQBoIqoA0ERUAaCJqAJAE9dT5ZC06rTnT5r/61/90blnr3jjRyet/QvHPTJpflldvnX9pPnPvu+suWdPuOG2SWvDM5ypAkATUQWAJqIKAE32GdWqOqWqPlNV91bVPVX1ttnta6rqlqq6f/b3CQd+uwCwuPbnTPXpJJeOMV6c5Kwkb62qFye5LMmtY4wzktw6+x4ADlv7jOoYY8sY487Z108kuS/JyUkuSHLD7GE3JHndAdojACyFZ/UjNVV1apKXJ7k9ydoxxpbZXQ8nWbuHmQ1JNiTJ0Tlm7o0CwKLb7w8qVdVxST6e5O1jjG/vet8YYyQZu5sbY1wzxlg/xli/OkdN2iwALLL9impVrc7OoH5ojPGJ2c1bq+qk2f0nJdl2YLYIAMthfz79W0k+mOS+McZVu9x1U5KLZ19fnORT/dsDgOWxP++pvjLJLyf5SlXdNbvt8iRXJvmDqvq1JN9I8oYDskMAWBL7jOoY4y+S1B7uPrd3OwCwvPxGJQBoIqoA0MSl3zhgVp3645PmH/8nJ809+8b//KeT1v5XP/KJfT/oEHTplvkvn5Ykt/33+S/ftub6/zFp7RN2uHwbK8+ZKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATUQVAJqIKgA0EVUAaCKqANBEVAGgiagCQBNRBYAmogoATVxP9RC36qR/NGn+0euOnXv210/77KS1Lzp+66T5ZXXJ5rPnnr3z6nWT1j7xxrsnza95wjVNObw5UwWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQxKXfDoLv/7P10+b/9aNzz17+gpsnrX3eP/jupPlltXX79+aefdVNl05a+4X/8a/mnl3z2LRLr+2YNA04UwWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoInrqR4Em1437f9dvvayjzXt5OD6wGOnT5p/32fPm3u2ttektV/4rq/PPXvG1tsnrb190jSwkpypAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJqIKAE1EFQCaiCoANBFVAGhSY4yDtthzas14RZ170NYDgG6fHjfeMcZYv7v7nKkCQBNRBYAmogoATfYZ1ao6pao+U1X3VtU9VfW22e1XVNXmqrpr9ue1B367ALC4Vu3HY55OcukY486qOj7JHVV1y+y+3x5jvOfAbQ8Alsc+ozrG2JJky+zrJ6rqviQnH+iNAcCyeVbvqVbVqUlenuT22U2XVNWXq+q6qjqhe3MAsEz2O6pVdVySjyd5+xjj20muTnJ6knXZeSb73j3MbaiqjVW18ak8OX3HALCg9iuqVbU6O4P6oTHGJ5JkjLF1jLF9jLEjybVJztzd7BjjmjHG+jHG+tU5qmvfALBw9ufTv5Xkg0nuG2NctcvtJ+3ysAuT3N2/PQBYHvvz6d9XJvnlJF+pqrtmt12e5KKqWpdkJNmU5M0HYH8AsDT259O/f5GkdnPXzf3bAYDl5TcqAUATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJqIKAE1EFQCaiCoANBFVAGgiqgDQRFQBoImoAkATUQWAJjXGOHiLVf1tkm/s5SEnJnnkIG3nUOGYzcdxm4/j9uw5ZvNZ5OP2/DHGc3d3x0GN6r5U1cYxxvqV3scycczm47jNx3F79hyz+SzrcfPyLwA0EVUAaLJoUb1mpTewhByz+Thu83Hcnj3HbD5LedwW6j1VAFhmi3amCgBLayGiWlXnV9VXq+qBqrpspfezLKpqU1V9paruqqqNK72fRVVV11XVtqq6e5fb1lTVLVV1/+zvE1Zyj4tmD8fsiqraPHu+3VVVr13JPS6iqjqlqj5TVfdW1T1V9bbZ7Z5ve7CXY7aUz7cVf/m3qo5I8rUkr0nyUJIvJrlojHHvim5sCVTVpiTrxxiL+rNcC6GqXpXkO0l+b4zx0tlt/yXJo2OMK2f/I3fCGOMdK7nPRbKHY3ZFku+MMd6zkntbZFV1UpKTxhh3VtXxSe5I8rokvxLPt93ayzF7Q5bw+bYIZ6pnJnlgjPHgGOP7ST6a5IIV3hOHkDHG55I8+gM3X5DkhtnXN2Tnf8TM7OGYsQ9jjC1jjDtnXz+R5L4kJ8fzbY/2csyW0iJE9eQkf7PL9w9liQ/oQTaS/HlV3VFVG1Z6M0tm7Rhjy+zrh5OsXcnNLJFLqurLs5eHvYS5F1V1apKXJ7k9nm/75QeOWbKEz7dFiCrzO3uM8TNJfj7JW2cv2fEsjZ3vgfgY/L5dneT0JOuSbEny3hXdzQKrquOSfDzJ28cY3971Ps+33dvNMVvK59siRHVzklN2+f7HZrexD2OMzbO/tyX5ZHa+lM7+2Tp7L+eZ93S2rfB+Ft4YY+sYY/sYY0eSa+P5tltVtTo74/ChMcYnZjd7vu3F7o7Zsj7fFiGqX0xyRlWdVlVHJnlTkptWeE8Lr6qOnb2pn6o6Nsl5Se7e+xS7uCnJxbOvL07yqRXcy1J4JgozF8bz7e+pqkrywST3jTGu2uUuz7c92NMxW9bn24p/+jdJZh+V/q9Jjkhy3Rjj3Su7o8VXVT+RnWenSbIqyYcdt92rqo8kOSc7r3qxNck7k/xhkj9I8uPZeeWkN4wxfDBnZg/H7JzsfCluJNmU5M27vE9Ikqo6O8nnk3wlyY7ZzZdn53uEnm+7sZdjdlGW8Pm2EFEFgEPBIrz8CwCHBFEFgCaiCgBNRBUAmogqADQRVQBoIqoA0ERUAaDJ/wWMJAzCokb/jAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12401588",
   "metadata": {},
   "source": [
    "### Creating a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b681e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding=\"valid\", activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding=\"valid\", activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding=\"valid\", activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aed180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15488)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1982592   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,002,698\n",
      "Trainable params: 2,002,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967afe8a",
   "metadata": {},
   "source": [
    "- Observations:\n",
    "     1. With each layers Covnvulation layes the size of image is reduceing as we select no padding each new image is reduce by formula (size-padding + 1)\n",
    "     2. here Strident = (1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50258766",
   "metadata": {},
   "source": [
    "### Convulation with strident and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a38f53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding=\"same\", activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding=\"same\", activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding=\"same\", activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0c7df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,231,498\n",
      "Trainable params: 3,231,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d764e1",
   "metadata": {},
   "source": [
    "- Observations:\n",
    "    1. As we add pdding with image it did not reduce the size of image\n",
    "    2. output shape in each layer did not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceeff52",
   "metadata": {},
   "source": [
    "### CNN with Strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f9a5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb7f2f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,770\n",
      "Trainable params: 85,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7cc57",
   "metadata": {},
   "source": [
    "- we use strid to reduce calculation and make process fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f03387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
